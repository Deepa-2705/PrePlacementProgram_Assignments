{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217d5ec6-7519-41be-bf67-508e5af1e64a",
   "metadata": {},
   "source": [
    "Que 1. Can you explain the concept of feature extraction in convolutional neural networks (CNNs)?\n",
    "\n",
    "Ans: The neural network for feature extraction includes convolution layer piles and sets of pooling layers. As its name implies, the convolution layer transforms the image using the process of the convolution. It can be described as a series of digital filters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c74161-e2d8-4871-9ad4-7a82e0eebd43",
   "metadata": {},
   "source": [
    "Que 2. How does backpropagation work in the context of computer vision tasks?\n",
    "\n",
    "Ans: Backpropagation is the essence of neural net training. It is the practice of fine-tuning the weights of a neural net based on the error rate (i.e. loss) obtained in the previous epoch (i.e. iteration.) Proper tuning of the weights ensures lower error rates, making the model reliable by increasing its generalization.\n",
    "\n",
    "Backpropagation has two phases. The first one is the calculation of the gradient, or better, of the derivative of the loss function to each network's weigths. The second is the updating of them (delta rule). This last one can be performed with various optimization algorithms, to name a few Momentum, Adam etc …"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbb375b-62f6-48a2-86af-008a2ae35d66",
   "metadata": {},
   "source": [
    "Que 3. What are the benefits of using transfer learning in CNNs, and how does it work?\n",
    "\n",
    "Ans: Benefits:\n",
    "    \n",
    "1) It reduces the need for large labeled datasets by leveraging pre-trained models trained on extensive datasets like ImageNet. This is particularly advantageous when working with limited labeled data, making it feasible to train accurate models in scenarios with data scarcity.\n",
    "\n",
    "2) Transfer learning speeds up the training process. Pre-trained CNNs have already learned general features, so fine-tuning the model on a specific task requires less time compared to training from scratch. It also reduces the computational resources needed for training.\n",
    "\n",
    "3) Transfer learning allows models to generalize well to new tasks and datasets. By leveraging knowledge gained from pre-training, the models can capture meaningful representations and improve performance on specific tasks.\n",
    "\n",
    "* Transfer learning means taking the relevant parts of a pre-trained machine learning model and applying it to a new but similar problem. This will usually be the core information for the model to function, with new aspects added to the model to solve a specific task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f135b701-39ce-4968-8051-a70a85062fb1",
   "metadata": {},
   "source": [
    "Que 4. Describe different techniques for data augmentation in CNNs and their impact on model performance.\n",
    "\n",
    "Ans: Data Augmentation Techniques:\n",
    "\n",
    "1) Audio Data Augmentation\n",
    "    * Noise injection: add gaussian or random noise to the audio dataset to improve the model performance. \n",
    "    \n",
    "    * Shifting: shift audio left (fast forward) or right with random seconds.\n",
    "    \n",
    "    * Changing the speed: stretches times series by a fixed rate.\n",
    "    \n",
    "    * Changing the pitch: randomly change the pitch of the audio. \n",
    "    \n",
    "2) Text Data Augmentation\n",
    "\n",
    "    * Word or sentence shuffling: randomly changing the position of a word or sentence. \n",
    "    \n",
    "    * Word replacement: replace words with synonyms.\n",
    "\n",
    "    * Syntax-tree manipulation: paraphrase the sentence using the same word.\n",
    "\n",
    "    * Random word insertion: inserts words at random. \n",
    "\n",
    "    * Random word deletion: deletes words at random.\n",
    "    \n",
    "3) Image Augmentation\n",
    "\n",
    "    * Geometric transformations: randomly flip, crop, rotate, stretch, and zoom images. You need to be careful about applying multiple transformations on the same images, as this can reduce model performance. \n",
    "\n",
    "    * Color space transformations: randomly change RGB color channels, contrast, and brightness.\n",
    "\n",
    "    * Kernel filters: randomly change the sharpness or blurring of the image. \n",
    "\n",
    "    * Random erasing: delete some part of the initial image.\n",
    "\n",
    "    * Mixing images: blending and mixing multiple images. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff7ad12-e91a-4bf5-ba1e-4adfc54dbf0f",
   "metadata": {},
   "source": [
    "Que 5. How do CNNs approach the task of object detection, and what are some popular architectures used for this task?\n",
    "\n",
    "Ans: Object Recognition Neural Network Architectures created until now is divided into 2 main groups: Multi-Stage vs Single-Stage Detectors.\n",
    "\n",
    "1) Multi-Stage Detectors\n",
    "\n",
    "* RCNN 2014\n",
    "\n",
    "* Fast RCNN 2015\n",
    "\n",
    "* Faster RCNN 2015\n",
    "\n",
    "2) Single-Stage Detectors\n",
    "\n",
    "* SSD 2016\n",
    "\n",
    "* YOLO 2016\n",
    "\n",
    "* YOLOv2 2016, YOLOv3 2018, YOLOv4 2020, YOLOv5 2020\n",
    "\n",
    "* Region Proposal Extraction from Input Image using Selective Search\n",
    "\n",
    "The way the selective search algorithm works is that it applies a segmentation algorithm to find blobs in an image to figure out what could be an object. Selective search recursively combines these groups of regions together into larger ones to create 2,000 areas to be investigated.\n",
    "\n",
    "* Feature Extraction using CNN on each ROI comes from the previous step\n",
    "\n",
    "After extracting almost 2000 possible boxes which may have an object according to the segmentation, CNN is applied to all these boxes one by one to extract the features to be used for classification at the next step\n",
    "\n",
    "* Classification with SVM and Bounding Box Prediction\n",
    "\n",
    "Finally, using SVM (support vector machine) for classification and a bounding box regressor, the model gives us the final bounding boxes along with detected classes where the bounding box regressor’s task is just to improve the proposed box to encircle the object better.\n",
    "\n",
    "* SSD: Single Shot MultiBox Detector\n",
    "\n",
    "A standard pre-trained neural network is used as a feature extractor like VGG16, VGG19, or ResNet.\n",
    "\n",
    "After this CNN, some additional convolutional layers are applied to obtain the different sizes of feature maps. Some of these feature maps and the output maps from the feature extraction network are sent to the image classification part which consists of Fully Connected Layer after obtaining bounding boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c87f721-d16e-4805-aee2-f51913a6a203",
   "metadata": {},
   "source": [
    "Que 6. Can you explain the concept of object tracking in computer vision and how it is implemented in CNNs?\n",
    "\n",
    "Ans: Object tracking identifies objects and tracks them during series of frames on the footage or video stream. Object detection is a part of the object tracking process, more specifically, an initial stage when a neural network finds an object on the video or image and identifies it as the target one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0842d188-6039-4613-9ed3-b17f53b6472a",
   "metadata": {},
   "source": [
    "Que 7. What is the purpose of object segmentation in computer vision, and how do CNNs accomplish it?\n",
    "\n",
    "Ans: Technology is taking a transformation to fill up the empty shoes of services when humans are quarantined. That’s why extensive research and progress is going on in the field of Medical imaging and Self-driving cars which can help mankind in indoor and outdoor solutions.\n",
    "\n",
    "Object Segmentation is one such method that is being used in these intelligence systems and still, every day more and more papers and algorithms are developing.\n",
    "\n",
    "It involves dividing a visual input into segments to make image analysis easier. Segments are made up of sets of one or more pixels. Image segmentation sorts pixels into larger components while also eliminating the need to consider each pixel as a unit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c625b-0fc2-4ff2-9570-10bd327bc425",
   "metadata": {},
   "source": [
    "Que 8. How are CNNs applied to optical character recognition (OCR) tasks, and what challenges are involved?\n",
    "\n",
    "Ans: Convolutional Neural Networks (CNNs) are a type of deep learning model that is highly effective in image recognition tasks. OCR solutions that leverage CNNs can learn and generalize features from input images, making them capable of handling a wide range of text recognition scenarios.\n",
    "\n",
    "* Challenges:\n",
    "\n",
    "1) Computational resources: Training a CNN-based OCR model requires significant computational resources, making it less accessible for users with limited hardware.\n",
    "\n",
    "2) Longer setup time: Developing a CNN-based OCR solution requires more time for training and fine-tuning the model.3. Data dependency: The performance of a CNN-based OCR system is highly dependent on the quality and diversity of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94769b37-7dbf-483e-948d-34b8d8fe4f77",
   "metadata": {},
   "source": [
    "Que 9. Describe the concept of image embedding and its applications in computer vision tasks.\n",
    "\n",
    "Ans: Embeddings in computer vision are used for a wide range of tasks, including image classification, object detection and recognition, image retrieval, similarity, and video analysis. In image classification, embeddings are used to represent images and assign them to specific classes or labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021e6c42-0e5d-4e61-95ed-483dd507e101",
   "metadata": {},
   "source": [
    "Que 10. What is model distillation in CNNs, and how does it improve model performance and efficiency?\n",
    "\n",
    "Ans: Knowledge distillation refers to the idea of model compression by teaching a smaller network, step by step, exactly what to do using a bigger already trained network. The ‘soft labels’ refer to the output feature maps by the bigger network after every convolution layer. The smaller network is then trained to learn the exact behavior of the bigger network by trying to replicate it’s outputs at every level (not just the final loss).\n",
    "\n",
    "With model distillation, a separate inference-optimized model is trained using the training-optimized model, in a process known as distillation, where knowledge transfer happens. If done correctly, model distillation allows the inference-optimized model to keep almost all the quality of the training-optimized model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f13c50-a6bb-4952-85b5-626460ae7974",
   "metadata": {},
   "source": [
    "Que 11. Explain the concept of model quantization and its benefits in reducing the memory footprint of CNN models.\n",
    "\n",
    "Ans: Quantization for deep learning is the process of approximating a neural network that uses floating-point numbers by a neural network of low bit width numbers. This dramatically reduces both the memory requirement and computational cost of using neural networks.\n",
    "\n",
    "Quantization is an optimization technique that reduces the precision of the models parameters from 32-bit floating point values to 8-bit (int8) values without compromising the accuracy, resulting in a reduced model size, improved portability, and faster computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b249185-59cf-4222-b514-cf4a71f37d0b",
   "metadata": {},
   "source": [
    "Que 12. How does distributed training work in CNNs, and what are the advantages of this approach?\n",
    "\n",
    "Ans: In distributed training the workload to train a model is split up and shared among multiple mini processors, called worker nodes. These worker nodes work in parallel to speed up model training. Distributed training can be used for traditional ML models, but is better suited for compute and time intensive tasks, like deep learning for training deep neural networks.\n",
    "\n",
    "Distributed training has several benefits, including: \n",
    "\n",
    "Faster Training: By distributing the workload across multiple machines, distributed training can significantly reduce training time.\n",
    "\n",
    "Scalability: Distributed training can scale to handle larger datasets and more complex models than traditional training methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a917eb-53af-4618-8ad9-8f03442fd1e0",
   "metadata": {},
   "source": [
    "Que 13. Compare and contrast the PyTorch and TensorFlow frameworks for CNN development.\n",
    "\n",
    "Ans: PyTorch vs. TensorFlow\n",
    "    \n",
    "1) Origin\n",
    "\n",
    "PyTorch is a machine learning library which is based on Torch library. Facebook's artificial intelligence research group developed it for application, such as deep learning and natural language processing. It is free and open-source software which is released under the Modified BSD license. Tensor flow is also an open-source machine learning, which was initially developed by Google.\n",
    "\n",
    "2) Features\n",
    "\n",
    "PyTorch has several attracting features such as:\n",
    "\n",
    "Native support for Python\n",
    "\n",
    "Dynamic computation graphs\n",
    "\n",
    "Supports for CUDA\n",
    "\n",
    "These features ensure less time for running the code and increase in performance. On the other hand, TensorFlow has also distinguished and attracting features such as TensorBoard which will be a great option while visualizing a machine learning model. It also provides TensorFlow Serving, which is a specific grpc server which is used during the deployment during the production.\n",
    "\n",
    "3) Community\n",
    "\n",
    "PyTorch has much lesser community than TensorFlow. TensorFlow is adopted by many researchers of various fields such as business organization, academics, etc. In TensorFlow, it is easier to find for resources or solution.\n",
    "\n",
    "4) Level of API\n",
    "\n",
    "If we will talk about the API, then the TensorFlow is the best one because it provides both high and low-level APIs. PyTorch provides lower-level API which focuses on the direct work with array expression. PyTorch has gained great interest in the last year and becoming a preferred solution for academic research and application of deep learning, which requires optimizing custom expression.\n",
    "\n",
    "5) Speed\n",
    "\n",
    "PyTorch and TensorFlow are two most popular deep learning framework. PyTorch is suitable if we are working in our home, and we are implementing our first deep learning project. But TensorFlow is used if we are working in our office, and we have an excellent knowledge of deep learning projects. If we compare both PyTorch and TensorFlow with their speed, then both the framework provides a similar pace, which is fast and suitable for performance.\n",
    "\n",
    "6) Ramp-Up Time\n",
    "\n",
    "PyTorch is a GPU enabled drop-in-replacement for NumPy which equipped higher-level functionality for building and training the deep neural network. If we are familiar with Python, NumPy, and deep learning abstraction, it makes PyTorch easy to learn. When we write TensorFlow code, it will first get \"compile\" into a graph by Python and then run by the TensorFlow execution engine. TensorFlow has a few extra concepts to learn, such as the graph, the session, placeholder, and variable scoping. The ramp-up time of TensorFlow is definitely longer than pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c220f45-b5fb-4a6b-a929-834d9ca522bb",
   "metadata": {},
   "source": [
    "Que 14. What are the advantages of using GPUs for accelerating CNN training and inference?\n",
    "\n",
    "Ans: \n",
    "    \n",
    "1) Memory bandwidth—including GPUs can provide the bandwidth needed to accommodate large datasets. This is because GPUs include dedicated video RAM (VRAM), enabling you to retain CPU memory for other tasks.\n",
    "\n",
    "2) Dataset size—GPUs in parallel can scale more easily than CPUs, enabling you to process massive datasets faster. The larger your datasets are, the greater benefit you can gain from GPUs.\n",
    "\n",
    "3) Optimization—a downside of GPUs is that optimization of long-running individual tasks is sometimes more difficult than with CPUs.\n",
    "\n",
    "4) GPUs can perform multiple, simultaneous computations. This enables the distribution of training processes and can significantly speed machine learning operations. With GPUs, you can accumulate many cores that use fewer resources without sacrificing efficiency or power."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fd8c65-8b1d-415c-bca5-a7a9177434f6",
   "metadata": {},
   "source": [
    "Que 15. How do occlusion and illumination changes affect CNN performance, and what strategies can be used to address these challenges?\n",
    "\n",
    "Ans: \n",
    "Occlusion often occurs when two or more objects come too close and seemingly merge or combine with each other. Image processing system with object tracking often wrongly track the occluded objects. Sometimes, after occlusion, the system will wrongly identify the initially tracked object as a new object\n",
    "\n",
    "* To tackle occlusions, image segmentation techniques can be implemented. Object detection and image segmentation are two important computer vision tasks. The main goal of object detection is to localize and recognize the object with a bounding box around it which provides a coarse representation of detected objects.\n",
    "\n",
    "The illumination across a scene usually varies slowly, while the reflectivity may vary rapidly from point to point. Thus illumination variations, or shading, give rise primarily to low-frequency Fourier components in an image, while reflectivity variations also give rise to high-frequency components."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61184232-b06d-4e07-9fa8-60c204c5d16d",
   "metadata": {},
   "source": [
    "Que 16. Can you explain the concept of spatial pooling in CNNs and its role in feature extraction?\n",
    "\n",
    "Ans: Spatial Pyramid Pooling (SPP) is a pooling layer that removes the fixed-size constraint of the network, i.e. a CNN does not require a fixed-size input image. Specifically, we add an SPP layer on top of the last convolutional layer.\n",
    "\n",
    "A CNN is a class of deep, feed-forward ANNs, most commonly applied to analyzing visual imagery. This type of DL model has been very popular recently due to the vast improvements in algorithms and computing capabilities.\n",
    "\n",
    "A CNN is a DNN that contains some layers within which convolutional operations are performed.\n",
    "\n",
    "Each neuron of the convolutional layer receives only a small portion of the outputs of the previous layer after convolving them with some “kernel.” The group of output values a neuron can see is called the “receptive field” of that neuron.\n",
    "\n",
    "The second main structure is the “pooling layer.” It combines each group of the outputs of the previous layer into a single neuron. There are two common variations of pooling operations: average pooling and max pooling . An average pooling layer averages its input values by taking the mean of them. On the other hand, max pooling takes the biggest value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b05e4e1-736d-400f-8238-612095b38afe",
   "metadata": {},
   "source": [
    "Que 17. What are the different techniques used for handling class imbalance in CNNs?\n",
    "\n",
    "Ans: Methods for addressing class imbalance can be divided into two main categories. The first category is data level methods that operate on training set. The other category covers classifier (algorithmic) level methods, which keeps the training dataset unchanged and adjust training or inference algorithms\n",
    "\n",
    "1.1 Data level methods\n",
    "\n",
    "a. Oversampling\n",
    "\n",
    "b. Undersampling\n",
    "\n",
    "1.2 Classifier level methods\n",
    "\n",
    "a. Thresholding\n",
    "\n",
    "b. Cost sensitive learning\n",
    "\n",
    "c. One-class classification\n",
    "\n",
    "d. Hybrid of methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d6f7de-2f3c-4694-ae47-428022a7c559",
   "metadata": {},
   "source": [
    "Que 18. Describe the concept of transfer learning and its applications in CNN model development.\n",
    "\n",
    "Ans: Transfer learning generally refers to a process where a model trained on one problem is used in some way on a second related problem.\n",
    "\n",
    "In deep learning, transfer learning is a technique whereby a neural network model is first trained on a problem similar to the problem that is being solved. One or more layers from the trained model are then used in a new model trained on the problem of interest.\n",
    "\n",
    "* Applications of Transfer Learning\n",
    "\n",
    "1) Natural language processing (NLP) Natural language processing refers to a system capable of comprehending and analyzing human language in audio or text files. \n",
    "\n",
    "2) Computer vision (CV) \n",
    "\n",
    "3) Neural networks. \n",
    "\n",
    "4) Autonomous driving industry. \n",
    "\n",
    "5) Gaming industry.\n",
    "\n",
    "6) Healthcare sector. \n",
    "\n",
    "7) Emails. \n",
    "\n",
    "8) Ecommerce industry."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eeada4e-3a9a-469a-879f-cd8a542052ff",
   "metadata": {},
   "source": [
    "Que 19. What is the impact of occlusion on CNN object detection performance, and how can it be mitigated?\n",
    "\n",
    "Ans: Occlusion often occurs when two or more objects come too close and seemingly merge or combine with each other. Image processing system with object tracking often wrongly track the occluded objects. Sometimes, after occlusion, the system will wrongly identify the initially tracked object as a new object \n",
    "\n",
    "To tackle occlusions, image segmentation techniques can be implemented. Object detection and image segmentation are two important computer vision tasks. The main goal of object detection is to localize and recognize the object with a bounding box around it which provides a coarse representation of detected objects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6459926-b73b-420c-98dd-064ce6570b12",
   "metadata": {},
   "source": [
    "Que 20. Explain the concept of image segmentation and its applications in computer vision tasks.\n",
    "\n",
    "Ans: Image segmentation aims to simplify and/or change the representation of an image into something more meaningful and easier to analyze. Here, each pixel is labeled. All the pixels belonging to the same category have a common label assigned to them.\n",
    "\n",
    "It is used for many practical applications including medical image analysis, computer vision for autonomous vehicles, face recognition and detection, video surveillance, and satellite image analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab78982-fc7f-4329-9b67-b1878da8436e",
   "metadata": {},
   "source": [
    "Que 21. How are CNNs used for instance segmentation, and what are some popular architectures for this task?\n",
    "\n",
    "Ans: \n",
    "\n",
    "1) The object detection algorithm first identifies the location of each object in the image, and then the CNN architecture segments each object separately. This is typically achieved using object detection algorithms like Faster R-CNN, RetinaNet, or YOLO. The object detection algorithm typically uses a region proposal network (RPN) to generate candidate object locations in the image. The RPN takes an image as input and outputs a set of bounding boxes that are likely to contain objects. Each bounding box is then passed through a classification network that predicts the class label of the object within the box and refines the location of the box to better fit the object. In the segmentation stage, CNNs are used to extract features from the region of interest (ROI) defined by the bounding box. The ROI is then fed into a fully convolutional network (FCN) to perform instance segmentation.\n",
    "\n",
    "2) Another approach for instance segmentation is Mask R-CNN, which combines object detection and segmentation in a single network. Mask R-CNN is an extension of the Faster R-CNN object detection framework, with an additional branch for generating object masks. The object detection branch identifies the object location and size, while the mask branch generates a binary mask for each object. \n",
    "\n",
    "* Computer vision deals with images, and image segmentation is one of the most important steps. It involves dividing a visual input into segments to make image analysis easier. Segments are made up of sets of one or more pixels. Image segmentation sorts pixels into larger components while also eliminating the need to consider each pixel as a unit. It is the process of dividing image into manageable sections or “tiles”. The process of image segmentation starts with defining small regions on an image that should not be divided. These regions are called seeds, and the position of these seeds defines the tiles. The picture below can be used to understand image classification, object detection and image segmentation. Notice how image segmentation can be used for image classification or object detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c4baf6-8638-4bea-951c-708808f5c721",
   "metadata": {},
   "source": [
    "Que 22. Describe the concept of object tracking in computer vision and its challenges.\n",
    "\n",
    "Ans: Object tracking is an application of deep learning where the program takes an initial set of object detections and develops a unique identification for each of the initial detections and then tracks the detected objects as they move around frames in a video.\n",
    "\n",
    "challenges: \n",
    "\n",
    "1) Object Localisation. \n",
    "\n",
    "2) Multiple Aspect Ratios and Spatial Sizes. \n",
    "\n",
    "3) Viewpoint Variation. \n",
    "\n",
    "4) Occlusion. \n",
    "\n",
    "5) Deformation. \n",
    "\n",
    "6) Intra-Class Variation. \n",
    "\n",
    "7) Limited Data. \n",
    "\n",
    "8) Cluttered or textured background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c45bfe-2534-4e48-b21b-5d564b3c318e",
   "metadata": {},
   "source": [
    "Que 23. What is the role of anchor boxes in object detection models like SSD and Faster R-CNN?\n",
    "\n",
    "Ans: An object detector that uses anchor boxes can process an entire image at once, making real-time object detection systems possible. Because a convolutional neural network (CNN) can process an input image in a convolutional manner, a spatial location in the input can be related to a spatial location in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342f7af3-760a-402a-87c0-c25b1ee7a987",
   "metadata": {},
   "source": [
    "Que 24. Can you explain the architecture and working principles of the Mask R-CNN model?\n",
    "\n",
    "Ans: Mask R-CNN, or Mask RCNN, is a Convolutional Neural Network (CNN) and state-of-the-art in terms of image segmentation and instance segmentation. Mask R-CNN was developed on top of Faster R-CNN, a Region-Based Convolutional Neural Network. The first step to understanding how Mask R-CNN work requires an understanding of the concept of Image Segmentation. The computer vision task Image Segmentation is the process of partitioning a digital image into multiple segments (sets of pixels, also known as image objects). This segmentation is used to locate objects and boundaries (lines, curves, etc.). \n",
    "\n",
    "There are 2 main types of image segmentation that fall under Mask R-CNN: \n",
    "\n",
    "1) Semantic Segmentation \n",
    "\n",
    "2) Instance Segmentation\n",
    "\n",
    "\n",
    "* Working :\n",
    "\n",
    "Mask R-CNN was built using Faster R-CNN. While Faster R-CNN has 2 outputs for each candidate object, a class label and a bounding-box offset, Mask R-CNN is the addition of a third branch that outputs the object mask. The additional mask output is distinct from the class and box outputs, requiring the extraction of a much finer spatial layout of an object. Mask R-CNN is an extension of Faster R-CNN and works by adding a branch for predicting an object mask (Region of Interest) in parallel with the existing branch for bounding box recognition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5ce1e7-1ca7-42e2-9abe-1aa607806694",
   "metadata": {},
   "source": [
    "Que 25. How are CNNs used for optical character recognition (OCR), and what challenges are involved in this task?\n",
    "\n",
    "Ans: Convolutional Neural Networks (CNNs) are a type of deep learning model that is highly effective in image recognition tasks. OCR solutions that leverage CNNs can learn and generalize features from input images, making them capable of handling a wide range of text recognition scenarios.\n",
    "\n",
    "* Challenges:\n",
    "\n",
    "1) Computational resources: Training a CNN-based OCR model requires significant computational resources, making it less accessible for users with limited hardware.\n",
    "\n",
    "2) Longer setup time: Developing a CNN-based OCR solution requires more time for training and fine-tuning the model.3. Data dependency: The performance of a CNN-based OCR system is highly dependent on the quality and diversity of the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4779932f-ade3-4b30-91f4-8c304d929a24",
   "metadata": {},
   "source": [
    "Que 26. Describe the concept of image embedding and its applications in similarity-based image retrieval.\n",
    "\n",
    "Ans: Image embedding is a vector representation of an image in which images with similar motives have similar vector profiles. Embedder transforms each image into one vector of numbers.\n",
    "\n",
    "The Embeddings for Image model generates 1024-dimension vectors based on the input you provide, which can include a combination of image data and/or text data. The embedding vectors can then be used for subsequent tasks like image classification or content moderation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79daaf92-7a7e-4171-a158-bf0eaef8fd07",
   "metadata": {},
   "source": [
    "Que 27. What are the benefits of model distillation in CNNs, and how is it implemented?\n",
    "\n",
    "Ans: Benefit:\n",
    "\n",
    "1) Lightweight and efficient models can be trained for downstream tasks instead of using a pre-trained, very complex model. This saves computational resources and allows deep networks to be deployed in mobile devices or embedded sensor nodes.\n",
    "\n",
    "2) The student model performs almost as well as the teacher network through Knowledge Distillation, which would not have been possible if the same student architecture was traditionally trained using the same training dataset.\n",
    "\n",
    "3) Knowledge Distillation can be used to boost the performance of adversarially robust models as a simple plugin method to improve the robustness and/or clean accuracy of state-of-the-art robust models.\n",
    "\n",
    "4) Knowledge Distillation enables training of the student model with less training data if the teacher model is already pre-trained."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b64b1eb-b461-40ec-a4ff-eebf01ea59ec",
   "metadata": {},
   "source": [
    "Que 28. Explain the concept of model quantization and its impact on CNN model efficiency.\n",
    "\n",
    "Ans: A quantized model executes some or all of the operations on tensors with reduced precision rather than full precision (floating point) values. This allows for a more compact model representation and the use of high performance vectorized operations on many hardware platforms.\n",
    "\n",
    "Color quantization reduces the number of colors used in an image; this is important for displaying images on devices that support a limited number of colors and for efficiently compressing certain kinds of images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c748fdb-dbef-4aa2-bda9-7923f4b5ca70",
   "metadata": {},
   "source": [
    "Que 29. How does distributed training of CNN models across multiple machines or GPUs improve performance?\n",
    "\n",
    "Ans:It is important to remember that one GPU for distributed training will need to host the collected data and results of the other GPUs during the training phase. You can run into the issue of one GPU running out of memory if you are not paying close attention.\n",
    "\n",
    "The training phase is the most resource-intensive part of building a neural network or machine learning model. A neural network requires data inputs during the training phase. The model outputs a relevant prediction based on processed data in layers based on changes made between datasets. The first round of input data essentially forms a baseline for the machine learning model to understand; subsequent datasets calculate weights and parameters to train machine prediction accuracy.\n",
    "\n",
    "For datasets that are simple or in a small number, waiting a couple of minutes is feasible. However, as the size or volume of input data increases, training times could reach hours, days, or even longer.\n",
    "\n",
    "CPUs struggle to operate on a large amount of data, such as repetitive calculations on hundreds of thousands of floating-point numbers. Deep neural networks are composed of operations like matrix multiplications and vector additions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4839b2-0918-45fc-a544-515417f65811",
   "metadata": {},
   "source": [
    "Que 30. Compare and contrast the features and capabilities of PyTorch and TensorFlow frameworks for CNN development.\n",
    "\n",
    "Ans: PYTORCH PROS:\n",
    "\n",
    "1) Python-like coding.\n",
    "\n",
    "2) Dynamic graph.\n",
    "\n",
    "3) Easy and quick editing.\n",
    "\n",
    "4) Good documentation and community support.\n",
    "\n",
    "5) Open source.\n",
    "\n",
    "6) Plenty of projects out there using PyTorch.\n",
    "\n",
    "TENSORFLOW PROS:\n",
    "\n",
    "1) Simple built-in high-level API.\n",
    "\n",
    "2) Visualizing training with Tensorboard.\n",
    "\n",
    "3) Production-ready thanks to TensorFlow serving.\n",
    "\n",
    "4) Easy mobile support.\n",
    "\n",
    "5) Open source.\n",
    "\n",
    "6) Good documentation and community support."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf21174-66fd-4e05-bd1b-7bda10ae9558",
   "metadata": {},
   "source": [
    "Que 31. How do GPUs accelerate CNN training and inference, and what are their limitations?\n",
    "\n",
    "Ans:\n",
    "* By batching instructions and pushing vast amounts of data at high volumes, they can speed up workloads beyond the capabilities of a CPU. In this way, GPUs provide massive acceleration for specialized tasks such as machine learning, data analytics, and other artificial intelligence (AI) applications.\n",
    "\n",
    "* GPUs have limited memory available for computations, and if the work-item load is too high, it can quickly exhaust the available memory. This can lead to memory errors and crashes, which can significantly impact the performance of your code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a67fdac-f054-4d5d-899e-53b45032ddc7",
   "metadata": {},
   "source": [
    "Que 32. Discuss the challenges and techniques for handling occlusion in object detection and tracking tasks.\n",
    "\n",
    "Ans: Challenges:\n",
    " \n",
    "1) Object Localisation. \n",
    "\n",
    "2) Multiple Aspect Ratios and Spatial Sizes. \n",
    "\n",
    "3) Viewpoint Variation. \n",
    "\n",
    "4) Occlusion. \n",
    "\n",
    "5) Deformation. \n",
    "\n",
    "6) Intra-Class Variation. \n",
    "\n",
    "7) Limited Data. \n",
    "\n",
    "8) Cluttered or textured background.\n",
    "\n",
    "* Typically, tracking methods handle occlusion by modelling the object motion using linear and non-linear dynamic models. The derived models will be used to continuously predicting the object location when a tracked object is occluded until the object reappears."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62e4cdf-567b-4f45-96c9-bfd5e0d9385f",
   "metadata": {},
   "source": [
    "Que 33. Explain the impact of illumination changes on CNN performance and techniques for robustness.\n",
    "\n",
    "Ans: The illumination across a scene usually varies slowly, while the reflectivity may vary rapidly from point to point. Thus illumination variations, or shading, give rise primarily to low-frequency Fourier components in an image, while reflectivity variations also give rise to high-frequency components.\n",
    "\n",
    "Illumination techniques comprise back lighting, diffuse (also known as full bright field) lighting, bright field (actually partial bright field or directional) lighting, and dark field lighting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e903eb83-7a54-491c-b734-21807a7398b7",
   "metadata": {},
   "source": [
    "Que 34. What are some data augmentation techniques used in CNNs, and how do they address the limitations of limited training data?\n",
    "\n",
    "Ans: Data augmentation is the addition of new data artificially derived from existing training data. Techniques include resizing, flipping, rotating, cropping, padding, etc. It helps to address issues like overfitting and data scarcity, and it makes the model robust with better performance.\n",
    "\n",
    "Data augmentation is a crucial technique in enhancing machine learning models by expanding and diversifying training datasets. With various techniques available for image and text data, data augmentation can significantly improve model performance and generalization capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5e61b1-2635-428c-9afc-5e8860ca23b9",
   "metadata": {},
   "source": [
    "Que 35. Describe the concept of class imbalance in CNN classification tasks and techniques for handling it.\n",
    "\n",
    "Ans: Class imbalance occurs when some classes are overrepresented or underrepresented in the training data, leading to biased predictions.\n",
    "\n",
    "The effect of class imbalance on classification performance is detrimental. To achieve the best accuracy, one should apply thresholding to compensate for prior class probabilities. A combination of thresholding with baseline and oversampling is the most preferable, whereas it should not be combined with undersampling.\n",
    "\n",
    "* Resampling Techniques to Solve Class Imbalance\n",
    "\n",
    "One of the widely adopted class imbalance techniques for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and/or adding more examples from the minority class (over-sampling)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af63ef48-72b8-482e-ad83-2b0b96a5bdaf",
   "metadata": {},
   "source": [
    "Que 36. How can self-supervised learning be applied in CNNs for unsupervised feature learning?\n",
    "\n",
    "Ans: Self-supervised learning (SSL) is an evolving machine learning technique poised to solve the challenges posed by the over-dependence of labeled data. For many years, building intelligent systems using machine learning methods has been largely dependent on good quality labeled data. Consequently, the cost of high-quality annotated data is a major bottleneck in the overall training process.\n",
    "\n",
    "In this process, the unsupervised problem is transformed into a supervised problem by auto-generating the labels. To make use of the huge quantity of unlabeled data, it is crucial to set the right learning objectives to get supervision from the data itself.\n",
    "\n",
    "The process of the self-supervised learning method is to identify any hidden part of the input from any unhidden part of the input. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c172317f-d504-4516-a604-3fc64308cce7",
   "metadata": {},
   "source": [
    "Que 37. What are some popular CNN architectures specifically designed for medical image analysis tasks?\n",
    "\n",
    "Ans: Best CNN Architecture For Image Processing\n",
    "\n",
    "1) Convolutional Layer:\n",
    "2) Pooling Layer:\n",
    "3) Fully Connected Layer:\n",
    "4) Best CNN Architecture.\n",
    "5) AlexNet.\n",
    "6) VGG-16.\n",
    "7) VGG-19.\n",
    "8) Inception and GoogLeNet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd6e49-fbda-4e58-8170-686f7efa99f4",
   "metadata": {},
   "source": [
    "Que 38. Explain the architecture and principles of the U-Net model for medical image segmentation.\n",
    "\n",
    "Ans: U-Net Architecture\n",
    "\n",
    "U-Net was introduced in the paper, U-Net: Convolutional Networks for Biomedical Image Segmentation. The model architecture is fairly simple: an encoder (for downsampling) and a decoder (for upsampling) with skip connections. As Figure 1 shows, it shapes like the letter U hence the name U-Net.\n",
    "\n",
    "The gray arrows indicate the skip connections that concatenate the encoder feature map with the decoder, which helps the backward flow of gradients for improved training.\n",
    "\n",
    "Principle \n",
    "\n",
    "Works efficiently on small datasets through heavy data augmentation as in some cases the number of annotated samples will be less.\n",
    "\n",
    "· Works for binary as well as multiple classes.\n",
    "\n",
    "· It is scale-invariant.\n",
    "\n",
    "· Can be used in a multitude of applications like Object Detection/Segmentation, GANs, etc.\n",
    "\n",
    "· The features extracted at different levels in the contracting path are then combined with the feature maps in the expansion path giving rise to more number of features which is necessary for an accurate segmentation map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb005eb-e228-40ba-84f0-8ea0766590cc",
   "metadata": {},
   "source": [
    "Que 39. How do CNN models handle noise and outliers in image classification and regression tasks?\n",
    "\n",
    "Ans: \n",
    "\n",
    "1) From the available literature, it is clear that CNN can considerably remove all kinds of noise from images and advance capability in image denoising. Several studies reported higher performance of CNN architecture for image denoising. CNN architectures support end-to-end procedures and are implemented promptly.\n",
    "\n",
    "2) CNN architecture can be customized for noise removal tasks creating patterns that remove the bottleneck of vanishing gradients.\n",
    "\n",
    "3) CNN methods are designed using technical knowledge and principles in concert with understanding the noise type and noise models.\n",
    "\n",
    "4) Most studies used pre-trained CNN models; however, noise properties are in a continuous nature and need a model built from scratch. Building such a model creates room for readjustment and fine-tuning. However, building a model from the beginning require lots of computation space and time. With the introduction of cloud-based methods (e.g., COLAB), it is hoped that the problem of space and time would be resolved.\n",
    "\n",
    "5) The use of spatial patterns in CNN architecture could create a shift from conventional methods to deep learning methods. Contrary to perceptions that CNN is a black box, features visualization methods provide a trusted platform for noise removal, however, the greatest challenge remains the computational time and space."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9ce498-07d6-4008-a100-34487087b6c8",
   "metadata": {},
   "source": [
    "Que 40. Discuss the concept of ensemble learning in CNNs and its benefits in improving model performance.\n",
    "\n",
    "Ans: Ensemble learning combines the predictions from multiple neural network models to reduce the variance of predictions and reduce generalization error. Techniques for ensemble learning can be grouped by the element that is varied, such as training data, the model, and how predictions are combined\n",
    "\n",
    "Advantages: \n",
    "\n",
    "1) More accurate prediction results- We can compare the working of the ensemble methods to the Diversification of our financial portfolios. It is advised to keep a mixed portfolio across debt and equity to reduce the variability and hence, to minimize the risk. Similarly, the ensemble of models will give better performance on the test case scenarios (unseen data) as compared to the individual models in most of the cases.\n",
    "\n",
    "2) Stable and more robust model- The aggregate result of multiple models is always less noisy than the individual models. This leads to model stability and robustness.\n",
    "\n",
    "3) Ensemble models capture linear as well as non-linear relationships in the data.Its accomplished by using 2 different models and forming an ensemble of the two."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93189674-2c10-41a5-89b5-c3c4f5ee42ac",
   "metadata": {},
   "source": [
    "Que 41. Can you explain the role of attention mechanisms in CNN models and how they improve performance?\n",
    "\n",
    "Ans: Channel attention In a convolutional neural network, each image is initially represented by three channels (R, G, B). After being processed by different convolution kernels, each channel will generate new channels containing different information.\n",
    "\n",
    "The attention mechanism was introduced to improve the performance of the encoder-decoder model for machine translation. The idea behind the attention mechanism was to permit the decoder to utilize the most relevant parts of the input sequence in a flexible manner, by a weighted combination of all the encoded input vectors, with the most relevant vectors being attributed the highest weights. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538b44c-980d-4258-9876-069ede94de48",
   "metadata": {},
   "source": [
    "Que 42. What are adversarial attacks on CNN models, and what techniques can be used for adversarial defense?\n",
    "\n",
    "Ans: The existence of adversarial attacks on convolutional neural networks (CNN) questions the fitness of such models for serious applications. The attacks manipulate an input image such that misclassification is evoked while still looking normal to a human observer -- they are thus not easily detectable.\n",
    "\n",
    "Meanwhile, various defensive techniques for adversarial sample detection/classification have been proposed recently, including heuristic and certificated defenses. Heuristic defense refers to a defense mechanism that performs well in defending specific attacks without theoretical accuracy guarantees."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e8fa6-55af-4b97-9745-8d778c776ba2",
   "metadata": {},
   "source": [
    "Que 43. How can CNN models be applied to natural language processing (NLP) tasks, such as text classification or sentiment analysis?\n",
    "\n",
    "Ans:  CNNs can be used for different classification tasks in NLP. A convolution is a window that slides over a larger input data with an emphasis on a subset of the input matrix. Getting your data in the right dimensions is extremely important for any learning algorithm.\n",
    "\n",
    "we design a suitable CNN architecture for the sentiment analysis task. We use 3 pairs of convolutional layers and pooling layers in this architecture. To the best of our knowledge, this is the first time that a 7-layers architecture model is applied using word2vec and CNN to analyze sentences' sentiment.\n",
    "\n",
    "CNN utilizes an activation function which helps it run in kernel (i.e) high dimensional space for neural processing. For Natural language processing, text classification is a topic in which one needs to set predefined classes to free-text documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264040e9-b6b3-468a-8c27-ea4bd391015b",
   "metadata": {},
   "source": [
    "Que 44. Discuss the concept of multi-modal CNNs and their applications in fusing information from different modalities.\n",
    "\n",
    "Ans: A Multimodal Convolutional Neural Network architecture with X-ray and CT images (Model 2). In the first model architecture, CNN consists of an input layer, convolutional layers, pooling layers, dropout layers and a classification layer.\n",
    "\n",
    "Specifically, multimodal systems can offer a flexible, efficient and usable environment allowing users to interact through input modalities, such as speech, handwriting, hand gesture and gaze, and to receive information by the system through output modalities, such as speech synthesis, smart graphics and other modalities, opportunely combined. Then a multimodal system has to recognize the inputs from the different modalities combining them according to temporal and contextual constraints in order to allow their interpretation. This process is known as multimodal fusion,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d827111-9a69-4eef-ba1d-fb37e83cda60",
   "metadata": {},
   "source": [
    "Que 45. Explain the concept of model interpretability in CNNs and techniques for visualizing learned features.\n",
    "\n",
    "Ans: Interpretability is about the extent to which a cause and effect can be observed within a system. Or to put it another way, it is the extent to which you are able to predict what is going to happen, given a change in input or algorithmic parameters.\n",
    "\n",
    "You can visualize what the learned features look like by using deepDreamImage to generate images that strongly activate a particular channel of the network layers. The example requires Deep Learning Toolbox™ and Deep Learning Toolbox Model for GoogLeNet Network support package."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba335640-2cfe-4304-9789-b876ce163c3f",
   "metadata": {},
   "source": [
    "Que 46. What are some considerations and challenges in deploying CNN models in production environments?\n",
    "\n",
    "Ans: \n",
    "    \n",
    "1) Lack of openness and explanation of the concept. This is one of the biggest obstacles. Unfortunately, the complexity and opacity of certain ML models make it challenging to grasp exactly how these systems arrive at their predictions, so it may be hard to put faith in the model analysis and provide enough justification for its actions when dealing with stakeholders.\n",
    "\n",
    "2) Adaptable to shifting data patterns. Models may be surprised by new information that wasn’t there during training if they’re put to use in a real-world setting. Consequences of this include idea drift (model’s accuracy gradually declines over time). This often necessitates retraining or updating the model, which may be laborious and resource-intensive.\n",
    "\n",
    "3) Processing massive amounts of data in real time. To produce predictions, many machine learning models need to handle massive volumes of data. This may be difficult to scale considering the potential strain on the system.\n",
    "\n",
    "4) Managing various deployment methods for machine learning models. Depending on the needs of the organization, machine learning models may be implemented locally, in the cloud, or even as a web service. All machine learning model deployment methods come with their own unique set of difficulties and prerequisites.\n",
    "\n",
    "5) Dealing with security and compliance. Because machine learning models often deal with private information, they must adhere to stringent rules and guidelines. It is the responsibility of the employing organization to guarantee the model’s safe and lawful implementation.\n",
    "\n",
    "6) Maintaining and monitoring the model throughout production. After you deploy the machine learning model to production, it is essential to monitor its health and look for any problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cbb1f6-9936-4a14-859c-adc6d21511c3",
   "metadata": {},
   "source": [
    "Que 47. Discuss the impact of imbalanced datasets on CNN training and techniques for addressing this issue.\n",
    "\n",
    "Ans:\n",
    "         \n",
    "    Data imbalance occurs when sample size from a class is very small or large then another class. Performance of predicted models is greatly affected when dataset is highly imbalanced and sample size increases. Overall, Imbalanced training data have a major negative impact on performance.\n",
    "\n",
    "    The impact of using class imbalanced training data samples is that it consumes twice the energy but reaches the same accuracy while training. The reason why data imbalance occurs is due to the sample size from one class being either too large or too small for the other class.\n",
    "\n",
    "* The effect of class imbalance on classification performance is detrimental. To achieve the best accuracy, one should apply thresholding to compensate for prior class probabilities. A combination of thresholding with baseline and oversampling is the most preferable, whereas it should not be combined with undersampling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6ef197-297b-41c4-9722-5707c0293e7a",
   "metadata": {},
   "source": [
    "Que 48. Explain the concept of transfer learning and its benefits in CNN model development.\n",
    "\n",
    "Ans: Transfer learning in a CNN refers to using a pre-trained model on a similar task as a starting point for training a new model on a different task.\n",
    "\n",
    "Benefits:\n",
    "\n",
    "Transfer learning allows developers to circumvent the need for lots of new data. A model that has already been trained on a task for which labeled training data is plentiful will be able to handle a new but similar task with far less data. There are other benefits of transfer learning through deep learning as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c80e47-9f6a-4ee4-a9be-c7800c53e02e",
   "metadata": {},
   "source": [
    "Que 49. How do CNN models handle data with missing or incomplete information?\n",
    "\n",
    "Ans: Popular strategies to handle missing values in the dataset\n",
    "\n",
    "1) Deleting Rows with missing values.\n",
    "\n",
    "2) Impute missing values for continuous variable.\n",
    "\n",
    "3) Impute missing values for categorical variable.\n",
    "\n",
    "4) Other Imputation Methods.\n",
    "\n",
    "5) Using Algorithms that support missing values.\n",
    "\n",
    "6) Prediction of missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde0f28a-11b5-47a1-99ca-ef12fcb0462e",
   "metadata": {},
   "source": [
    "Que 50. Describe the concept of multi-label classification in CNNs and techniques for solving this task.\n",
    "\n",
    "Ans: \n",
    "\n",
    "    It is used when there are two or more classes and the data we want to classify may belong to none of the classes or all of them at the same time, e.g. to classify which traffic signs are contained on an image\n",
    "\n",
    "* There are two main methods for tackling a multi-label classification problem: problem transformation methods and algorithm adaptation methods. Problem transformation methods transform the multi-label problem into a set of binary classification problems, which can then be handled using single-class classifiers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
